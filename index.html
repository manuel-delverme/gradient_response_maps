<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">

		<link rel="stylesheet" href="lib/css/zenburn.css">

		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
                    <section>
                        What are LINE-{2D, 3D, MOD} bringing to object detection?
                        <p>
                        <span class="fragment">Gradient Response Maps </span><span class="fragment"> for Real-Time </span><span class="fragment">Detection of Texture-Less Objects</span>
                        </p>
                            <img class="fragment" src="docs/textureless.png"/>
                            <aside class="notes"> few points of interest (doesn't allow for optimization in pixel search space) lack of texture, unreliable descriptors</aside>
                        </p>
                    </section>
                    <section>
                        <p>
                            The real world is cluttered
                        </p>
                        <p class="fragment">
                            <img width="45%" src="docs/sapienza.jpg" /> <img width="45%" src="docs/comau.jpg" />
                            False positives, no space decomposition, no grid search
                        </p>
                        <aside class="notes">robust in.. </aside>
                    </section>
                    <section>
                        <p> We achieve milliseconds speeds by:
                        </p>
                        <ol>
                            <li class="fragment"> Rough quantization for gradient orientations, 8 bins </li>
                            <li class="fragment">Information spreading </li>
                        </ol>
                    </section>
                    <section>
                        <p>
                            Quantization<br/>
                            <img src="docs/quantization.png">
                        </p>
                        <p class="fragment">
                            the Quantization operation creates a finite domain
                            map 3x[0, 255] to [0, 8)
                        </p>
                    </section>
                    <section>
                        <p>
                        the Quantization operation creates a <b>finite domain</b>
                        </p>
                        <p class="fragment">
                             a finite domain enables look up tables and pre-calculation!
                        </p>
                    </section>
                    <section>
                        <p>
                            Information spreading
                        </p>
                        <p class="fragment">
                            <img width="100%" src="docs/spread_operation.png">
                        </p>
                    </section>
                    <section>
                        you also get memory linearization (fewer cache misses) and <b>SSE</b> parallelization for free*
                    </section>
                </section>
                <section>
                    <section>
                        <p>We bring three algorithms: </p>
                        <p class="fragment">LINE-2D uses the image gradients only RGB</p>
                        <p class="fragment">LINE-3D that uses the surface normals Depth</p>
                        <p class="fragment">LINE-MOD, RGB+D</p>
                    </section>
                    <section>
                        LINE-2D (modality 0, colors)
                        <p class="">
                            <img src="docs/quantized_colors.png">
                        </p>
                    </section>
                    <section>
                        LINE-2D (modality 0, colors)
                        <p class="">
                            <img src="docs/duck_color_gradients.png"> <br/>
                            note: they appear in the contour
                        </p>
                    </section>
                    <section>
                        LINE-3D (modality 1, depth)
                        <p class="">
                            <img src="docs/quantized_normals.png">
                        </p>
                    </section>
                    <section>
                        LINE-3D (modality 1, depth)
                        <p class="">
                        <img src="docs/duck_surface_normals.png"><br/> note: mostly they appear inside the object
                        </p>
                    </section>
                    <section>
                        LINE-MOD (modality 0+1)
                        <img src="docs/both_modalities.png">
                        <p class="fragment">
                            <img src="docs/this_is_a_duck.png">
                        </p>
                    </section>
                </section>
                <section>
                    <section>
                        <p>
                        Linemod uses template matching:
                        </p>
                        <p class="fragment">
                        Training phase:
                        </p>
                        <ol>
                            <li class="fragment">N different camera poses </li>
                            <li class="fragment">sobel filter (color) and tailor series* (depth)</li>
                            <li class="fragment">some filtering (grouping, averaging, drop edge normals)</li>
                            <li class="fragment">quantization as seen before</li>
                        </ol>
                    </section>
                    <section>
                        <p>
                            Build a response map
                        </p>
                        <p class="fragment"> 1) Feature spreading<br/> <img src="docs/spread_operation.png"></p>
                    </section>
                    <section>
                            <p class=""> 2) bit encoding of the orientations (SSE friendly)</p>
                            <img src="docs/binarization.png">
                    </section>
                    <section>
                        <p class="">
                            Cache the similarity results
                        </p>
                        <img width="100%" src="docs/similarity.png" />
                        <p class="">
                            store in a lookup table
                        </p>
                    </section>
                    <section>
                        calculating the response:
                        <ol>
                            <li> apply the quantize operation</li>
                            <li> <code> response_strenght = lookup_table_UP[01110] </code> </li>
                        </ol>
                    </section>
                    <section>
                        <p class="">
                            Detection:
                            <ol>
                                <li> thanks to spreading we just look at every $SPREAD_RADIUS pixel </li>
                                <li> Store responses $SPREAD_RADIUS apart in continuous memory addresses </li>
                                <li> Avoids cache misses on memory reads </li>
                            </ol>
                        </p>
                    </section>
                    <section>
                        <p>TP-TN</p>
                        <img class="" src="docs/results.png"/>
                    </section>
                    <section>
                        <p>Speed</p>
                        <img class="" src="docs/speed_results.png"/>
                    </section>
                </section>
				<section>
                    <section>
                        <ul>
                            <li>
                            Implemented in the major libraries (PCL, openCV) 
                            </li>
                            <li class="fragment">
                            6 years later LINE-MOD is still used as benchmark for novel algorthms
                            </li>
                            <li class="fragment">
                                Hinterstoisser writes very elegant c++ code (openCV)
                            </li>
                        <ul>
                    </section>
                </section>
			</div>
		</div>
            <script src="lib/js/head.min.js"></script>
            <script src="js/reveal.js"></script>
            <script>
                // More info about config & dependencies:
                // - https://github.com/hakimel/reveal.js#configuration
                // - https://github.com/hakimel/reveal.js#dependencies
                Reveal.initialize({
                    dependencies: [
                        { src: 'plugin/markdown/marked.js' },
                        { src: 'plugin/markdown/markdown.js' },
                        { src: 'plugin/notes/notes.js', async: true },
                        { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
                    ],
                    controlsTutorial: false,
                });
            </script>
	</body>
</html>
