<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
                    <section>
                        Why we put robots into the learning process?
                        <aside class="notes">SCALE</aside>
                        <ui style="text-align:left">
                            <li class="fragment">
                                Robots scale
                                <aside class="notes">CHEAPER</aside>
                            </li>
                            <li class="fragment">
                                Cheaper to train than a teacher
                                <aside class="notes">ADAPTS</aside>
                            </li>
                            <li class="fragment">
                                Student-paced, adaptive software.
                                <aside class="notes">IMPROVES</aside>
                            </li>
                            <li class="fragment">
                                Education can only improve with time
                                <aside class="notes">INDIA, AFRICA</aside>
                            </li>
                            <li class="fragment">
                                Raises the lowest common denominator for education
                                <aside class="notes">PEERS</aside>
                            </li>
                            <li class="fragment">
                                Robots as peers
                                <aside class="notes">WHAT WE DO</aside>
                            </li>
                        </ui>
                    </section>
                    <section>
                        Robots are socially inept:<br/>
                        <p class="fragment">
                            This influences their credibility as an educators
                        </p>
                    </section>
                </section>
                <section>
                    <section>
                        Platform
                        <img src="tega-full.jpg"/>
                    </section>
                    <section>
                        What is this work is aimed at?
                        <p class="fragment">
                            Help children improve language proficiency through storytelling
                        </p>
                        <p class="fragment">
                            How to be a good conversationalist?
                        </p>
                        <p class="fragment">
                            "Let them do all the talking" -cit somebody
                        </p>
                    </section>
                    <section>
                        How are we achieving that?
                        <p class="fragment">
                            We use backchannels (mmh, yea, go on.. etc.) to keep the student engaged
                        </p>
                        <p class="fragment">
                            Narrated stories will be longer
                        </p>
                    </section>
                    <section>
                        Methodology, the first step
                        <ul>
                        <li class="fragment">
                            Answer "How do Children (4-6 yo.) request and understand feedback requests?"
                        </li>
                        <li class="fragment">
                            Identify principal backchanneling behaviours
                        </li>
                        <li class="fragment">
                            identify speaker cues for feedback
                        </li>
                        <li class="fragment">
                            Characterize the bidirectionality of nonverbal behaviours (i.e., can children decode what they encode?)
                        </li>
                        </ul>
                    </section>
                    <section>
                        Methodology, second step
                        <p class="fragment">
                            Define the robot's action space based children behaviours
                        </p>
                        <p class="fragment">
                            Design backchanneling opportunity prediction (BOP) model to understand cues
                        </p>
                        <p class="fragment">
                            embed the BOP model on a social robot and measure
                        </p>
                    </section>
                    <section>
                        Results:
                        <p class="fragment">
                            It works!
                        </p>
                        <p class="fragment">
                            Children do perceive the BOP augmented robot as a more attentive listener than the non BOP robot
                        </p>
                    </section>
                </section>
				<section>
                    <section>
                        What is Backchannel?
                        <ul class="fragment" style="text-align:left">
                            <li> Nonverbal listener response behaviors</li>
                            <li> Gaze lockin</li>
                            <li> Noddin</li>
                            <li> Utterances (such as yeah, ok, uh huh, mhmm</li>
                        </ul>
                    </section>
                    <section>
                        Part of the communication protocol:<br/>
                        Backchanneling an important signal for both parties to communicate interest, understanding (or lack thereof), and error correction, and sentence completion.
                    </section>
                </section>
				<section>
				    <section>
                        since this is a two-way conversation and  we can't just randomly utter "mmh"
                        <br/>Without looking at the content of the speech (!)
				    </section>
				    <section>
                        we use some features: <br/>
                        voice activity detection (VAD)<br/>
                        energy<br/>
                        pitch<br/>
                        low pitch located toward the end of an utterance.<br/>
                        gaze<br/>
                    </section>
                </section>
				<section>
				    <section>
                    Results:
                        32 children from kindergarten, data from 20 children 
                        (age M = 6.25, SD = 1.33; 45% female)
                        Age was 5.22 years-old
                        3 rounds of storytelling with different over a span of five weeks<br/>
                    <img class="fragment" src="results.png"/>
                    </section>

                </section>
				<section>
				    <section>
                    The Model

                    Rule Based:
                    Combinations of features:
                        wordy & pause
                        long pause
                        pitch & pause
                        and energy & pause

				    </section>
				    <section>
                        <img src="models.png"/>
                        Wordy Model:
                        &gt;1.5s of speech, &gt;800ms of pause [Cooldown of 1.3s]
				    </section>
				    <section>
                        <img src="models.png"/>
                        Long Pause Model:
                        1.0s of speech followed by a pause of 1.7s length [Cooldown of 1.3s]
				    </section>
				    <section>
                        <img src="models.png"/>
                        Pitch Model:
                        a falling or rising pitch change that is followed by a pause
                        1.0s of speech, 400ms pitch falling/rising by 25% for 300ms [CD 1.3s]
				    </section>
				    <section>
                        <img src="models.png"/>
                        Energy Model:
                        a slope for 500ms,k300ms of pause, 30% slope. [CD 1.3s]
				    </section>
                </section>
                <section>
                    <a href="https://www.dropbox.com/sh/uo9gta3wd1qug2w/AAA-y0vlOepu2p2Sqtm4e8cTa?dl=0"> video! </a>
                </section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				],
                controlsTutorial: false,
			});
		</script>
	</body>
</html>
